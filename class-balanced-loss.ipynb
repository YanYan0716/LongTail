{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"about data long-tailed/data imbalance\n\nreference：https://github.com/richardaecn/class-balanced-loss\n\npaper：Class-Balanced Loss Based on Effective Number of Samples\n\n\npytorch==1.9.0\n\n\nyou can only run this code without any other prepare,some important part have test code to compare with offical tf version\n\n\nMost parameters are the same with tf's version, but this version's acc is slightly higher than tf, may beceuse of some random. \n\n\nIf there is any problem, i will try to modify in time\n\ndataset: cifar10 with imbalanced distribution","metadata":{"id":"CbwYbRum9_ur"}},{"cell_type":"code","source":"!pip3 install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(torch.__version__)","metadata":{"id":"F3lh2xqy6XMO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model\n","metadata":{"id":"1del5JKqJSdz"}},{"cell_type":"code","source":"NUM_LAYERS = 32\nRESNET_VERSION = 'v1'\nBATCH_NORM_EPSILON = 1e-5\nBATCH_NORM_DECAY = 0.9\nLOSS_TYPE = 'softmax'\nclass Residual_v1(nn.Module):\n    def __init__(self, in_filter, out_filter, stride, activate_before_residual=False):\n        super(Residual_v1, self).__init__()\n        if stride == 1:\n            self.padding = 'same'\n        else:\n            self.padding = 'valid'\n        \n        self.kernel_size = 3\n        self.in_filter = in_filter\n        self.out_filter = out_filter\n        self.conv1 = nn.Conv2d(\n            in_channels=in_filter,\n            out_channels=out_filter,\n            kernel_size=3,\n            stride=stride,\n            padding=self.padding,\n            bias=False,\n        )\n        self.bn1 = nn.BatchNorm2d(num_features=out_filter)\n        self.relu1 = nn.ReLU()\n\n        self.conv2 = nn.Conv2d(\n            in_channels=out_filter,\n            out_channels=out_filter,\n            kernel_size=3,\n            stride=1,\n            padding='same',\n            bias=False,\n        )\n        self.bn2 = nn.BatchNorm2d(num_features=out_filter)\n\n        if in_filter != out_filter:\n            self.avg_pool = nn.AvgPool2d(kernel_size=(stride, stride), stride=stride, ceil_mode=True)\n        self.relu2 = nn.ReLU()\n\n    def forward(self, x):\n        orig_x = x\n        if self.padding == 'valid':\n            pad = self.kernel_size - 1\n            pad_beg = pad // 2\n            pad_end = pad - pad_beg\n            p2d=(pad_beg, pad_end, pad_end, pad_beg, )\n            x=F.pad(x, p2d, 'constant', 0)\n            x = self.conv1(x)\n        else:\n            x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu1(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n        if self.in_filter != self.out_filter:\n            orig_x = self.avg_pool(orig_x)\n            pad = (self.out_filter-self.in_filter) // 2\n            p2d = (0, 0, 0, 0, pad, pad)\n            orig_x = F.pad(orig_x, p2d, 'constant', 0)\n\n        x = self.relu2(torch.add(x, orig_x))\n        return x","metadata":{"id":"SdMqrscuSTi0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"test pad\"\"\"\n# import tensorflow as tf\n# import numpy as np\n# import torch.nn.functional as F\n# in_filter=4\n# out_filter=8\n# pad=(out_filter-in_filter)//2\n\n# img = np.random.normal(size=(2, 4, 24, 24))\n# a=tf.convert_to_tensor(img)\n# x=tf.pad(a, [[0, 0], [pad, pad], [0, 0], [0, 0]])\n# print(x.shape)\n# print(x[0, :, 1, 1])\n# print('----------------')\n\n# b=torch.from_numpy(img)\n# p2d=(0, 0, 0, 0, pad, pad)\n# out=F.pad(b, p2d, 'constant', 0)\n# print(out.shape)\n# print(out[0, :, 1, 1])\n\n\"\"\"test Resdual_v1\"\"\"\nimg = torch.randn(size=(2, 4, 224, 224))\nlayer = Residual_v1(\n    in_filter=4,\n    out_filter=8,\n    stride=2\n)\nc=layer(img)\nprint(c.shape)","metadata":{"id":"YUDs-VCL3k4c","outputId":"df442fa0-8ec0-4d47-9b3f-ab07c11ff4e4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Residual_v2(nn.Module):\n    def __init__(self, in_filter, out_filter, stride, activate_before_residual=False):\n        super(Residual_v2, self).__init__()\n        self.in_filter = in_filter\n        self.out_filter = out_filter\n        self.activate_before_residual = activate_before_residual\n        if stride == 1:\n            self.padding = 'same'\n        else:\n            self.padding = 1\n\n        self.bn1 = nn.BatchNorm2d(num_features=in_filter)\n        self.relu1 = nn.ReLU()\n        self.conv1 = nn.Conv2d(\n            in_channels=in_filter,\n            out_channels=out_filter,\n            kernel_size=3,\n            stride=stride,\n            padding=self.padding,\n            bias=False\n        )\n\n        self.bn2 = nn.BatchNorm2d(num_features=out_filter)\n        self.relu2 = nn.ReLU()\n        self.conv2 = nn.Conv2d(\n            in_channels=out_filter,\n            out_channels=out_filter,\n            kernel_size=3,\n            stride=1,\n            padding='same',\n            bias=False\n        )\n\n        if in_filter != out_filter:\n            self.avg_pool = nn.AvgPool2d(kernel_size=(stride, stride), stride=stride, ceil_mode=True)\n\n    def forward(self, x):\n        if self.activate_before_residual:\n            x = self.bn1(x)\n            x = self.relu(x)\n            orig_x = x\n        else:\n            orig_x = x\n            x = self.bn1(x)\n            x = self.relu1(x)\n\n        x = self.conv1(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n        x = self.conv2(x)\n\n        if self.in_filter != self.out_filter:\n            orig_x = self.avg_pool(orig_x)\n            pad = (self.out_filter-self.in_filter) // 2\n            p2d = (0, 0, 0, 0, pad, pad)\n            orig_x = F.pad(orig_x, p2d, 'constant', 0)\n        x = torch.add(x, orig_x)\n        return x\n","metadata":{"id":"94ZGAZvdZGoq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"test Residual_v2\"\"\"\nimg = torch.randn(size=(2, 4, 224, 224))\nlayer = Residual_v2(\n    in_filter=4,\n    out_filter=8,\n    stride=1\n)\nc=layer(img)\nprint(c.shape)","metadata":{"id":"d3o0v8b2A7PY","outputId":"658f27f8-2f6b-47e3-cfaa-9c338c1c316b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Bottlenet_residual_v2(nn.Module):\n    def __init__(self, in_filter, out_filter, stride, activate_before_residual=False):\n        super(Bottlenet_residual_v2, self).__init__()\n        self.in_filter = in_filter\n        self.out_filter = out_filter\n        self.activate_before_residual = activate_before_residual\n        self.bn1 = nn.BatchNorm2d(num_features=in_filter)\n        self.relu1 = nn.ReLU()\n        \n        self.conv1 = nn.Conv2d(\n            in_channels=in_filter,\n            out_channels=out_filter//4,\n            kernel_size=1,\n            stride=stride,\n            bias=False\n        )\n        \n        self.bn2 = nn.BatchNorm2d(num_features=out_filter//4)\n        self.relu2 = nn.ReLU()\n        self.conv2 = nn.Conv2d(\n            in_channels=out_filter//4,\n            out_channels=out_filter//4,\n            kernel_size=3,\n            stride=1,\n            padding='same',\n            bias=False\n        )\n\n        self.bn3 = nn.BatchNorm2d(num_features=out_filter//4)\n        self.relu3 = nn.ReLU()\n        self.conv3 = nn.Conv2d(\n            in_channels=out_filter//4,\n            out_channels=out_filter,\n            kernel_size=1,\n            stride=1,\n            bias=False\n        )\n\n        if in_filter != out_filter:\n            self.conv4 = nn.Conv2d(\n                in_channels=in_filter,\n                out_channels=out_filter,\n                kernel_size=1,\n                stride=stride,\n                bias=False\n            )\n\n    def forward(self, x):\n        if self.activate_before_residual:\n            x = self.bn1(x)\n            x = self.relu1(x)\n            orig_x = x\n        else:\n            orig_x = x\n            x = self.bn1(x)\n            x = self.relu1(x)\n        x = self.conv1(x)\n        \n        x = self.bn2(x)\n        x = self.relu2(x)\n        x = self.conv2(x)\n\n        x = self.bn3(x)\n        x = self.relu3(x)\n        x = self.conv3(x)\n        if self.in_filter != self.out_filter:\n            orig_x = self.conv4(orig_x)\n        \n        x = torch.add(x, orig_x)\n        return x","metadata":{"id":"51QKb3hSd2jz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"test Bottlenet_residual_v2\"\"\"\nimg = torch.randn(size=(2, 4, 224, 224))\nlayer = Bottlenet_residual_v2(\n    in_filter=4,\n    out_filter=8,\n    stride=1\n)\nc=layer(img)\nprint(c.shape)","metadata":{"id":"b3BVz70-Dc0S","outputId":"96ceaca8-aaa6-4576-bbf9-479097516309","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class cifarModel(nn.Module):\n    def __init__(\n        self, \n        in_channels,\n        num_layers, \n        is_training, \n        batch_norm_decay, \n        batch_norm_epsilon,\n        version='v1',\n        num_classes=10, \n        loss_type='softmax',\n    ):\n        super(cifarModel, self).__init__()\n        self.n = (num_layers-2) // 6\n        self.filters = [16, 16, 32, 64]\n        self.strides = [1, 2, 2]\n        self.version = version\n        self.loss_type = loss_type\n        self.num_classes = num_classes\n\n        self.conv1 = nn.Conv2d(\n            in_channels=in_channels,\n            out_channels=16,\n            kernel_size=3,\n            stride=1,\n            padding='same',\n            bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(\n            num_features=16,\n            eps=batch_norm_epsilon,\n            momentum=1.-batch_norm_decay\n        )\n        self.relu1 = nn.ReLU()\n\n        if self.version == 'v1':\n            res_func = Residual_v1\n        elif self.version == 'v2':\n            res_func = Residual_v2\n        else:\n            res_func = Bottlenet_residual_v2\n\n        # make block\n        self.main_block_list = []\n        for i in range(3):\n            for j in range(self.n):\n                if j == 0:\n                    self.main_block_list.append(\n                        res_func(self.filters[i], self.filters[i+1], self.strides[i])\n                    )\n                else:\n                    self.main_block_list.append(\n                        res_func(self.filters[i+1], self.filters[i+1], 1)\n                    )\n        self.main_block = nn.ModuleList(self.main_block_list)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.flatten = nn.Flatten()\n        if self.loss_type == 'softmax':\n            self.fully_connected = nn.Linear(\n                in_features=self.filters[-1],\n                out_features=self.num_classes,\n            )\n\n        elif self.loss_type == 'sigmoid' or self.loss_type == 'focal':\n            self.fully_connected = nn.Linear(\n                in_features=self.filters[-1],\n                out_features=self.num_classes,\n            )\n            nn.init.constant_(self.fully_connected.bias, -torch.log(torch.tensor(self.num_classes-1).to(DEVICE).to(torch.float32)))\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu1(x)\n        for i in range(len(self.main_block_list)):\n            x = self.main_block[i](x)\n        x = self.avgpool(x)\n        x = self.flatten(x)\n        x = self.fully_connected(x)\n        return x\n        ","metadata":{"id":"XVOU4GDFli4D","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cifarmodel=cifarModel( \n        in_channels=3,\n        num_layers=NUM_LAYERS, \n        is_training=True, \n        batch_norm_decay=0.9, \n        batch_norm_epsilon=1e-5,\n        version=RESNET_VERSION,\n        num_classes=10, \n        loss_type=LOSS_TYPE,\n    ).to(DEVICE)\n\"\"\"test cifarModel\"\"\"\n# img=torch.randn(size=(2, 3, 224, 224)).to(DEVICE)\n# y=cifarmodel(img)\n# print(y)\n# print(y.shape)\n# print(cifarmodel.fully_connected.bias)\n# nn.init.constant_(cifarmodel.fully_connected.bias, -torch.log(torch.tensor(63).to(DEVICE).to(torch.float32)))\n# print(cifarmodel.fully_connected.bias)","metadata":{"id":"Z7UmY1SaVIsO","outputId":"f97c103b-1d08-4e17-e6b1-11f0a0bbe253","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss\n","metadata":{"id":"5jubBOB9dZUV"}},{"cell_type":"code","source":"GAMMA = 1.\ndef focal_loss(labels, logits, alpha, gamma, loss_type):\n    def sigmoid_cross_entropy_with_logits(label, logit):\n        return torch.maximum(logit, logit*0)-(logit*label)+torch.log(1+torch.exp(-torch.abs(logits)))\n\n    cross_entropy = sigmoid_cross_entropy_with_logits(labels, logits)\n    if loss_type == 'sigmoid':\n        return cross_entropy\n    else:\n        if gamma == 0.0:\n            modulator = 1.0\n        else:\n            x = gamma*torch.log1p(torch.exp(-1.0*logits))\n            modulator = torch.exp(-gamma*labels*logits-x)\n        loss = modulator*cross_entropy\n        weighted_loss = alpha*loss\n        focal_loss = torch.sum(weighted_loss)\n        focal_loss /= torch.sum(labels)\n\n        return focal_loss","metadata":{"id":"CjeAnNX9dY1w","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"test focal_loss\"\"\"\nimport tensorflow as tf\nimport numpy as np\n\ndef tf_focal_loss(labels, logits, alpha, gamma):\n    with tf.name_scope('focal_loss'):\n        logits = tf.cast(logits, dtype=tf.float32)\n        cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(\n            labels=labels, logits=logits)\n        if gamma == 0.0:\n            modulator = 1.0\n        else:\n            modulator = tf.exp(-gamma * labels * logits - gamma * tf.math.log1p(\n              tf.exp(-1.0 * logits)))\n        loss = modulator * cross_entropy\n        weighted_loss = alpha * loss\n        focal_loss = tf.reduce_sum(weighted_loss)\n        focal_loss /= tf.reduce_sum(labels)\n    return focal_loss\n\n# logits = np.random.normal(size=(2, 10))\n# labels = np.random.normal(size=(2, 10))\n# tf_logits = tf.cast(tf.convert_to_tensor(logits), tf.float32)\n# tf_labels = tf.cast(tf.convert_to_tensor(labels), tf.float32)\n# tf_loss = tf_focal_loss(tf_labels, tf_logits, 1., 1.)\n# print(tf_loss)\n# print('----------------')\n\n# pt_logits = torch.from_numpy(logits)\n# pt_labels = torch.from_numpy(labels)\n# pt_loss = focal_loss(pt_labels, pt_logits, 1., 1.)\n# print(pt_loss)","metadata":{"id":"_3_xgGn4ip-e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"Fn8hqYxKsO3B"}},{"cell_type":"code","source":"import torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torch\n\nLABELS_MAP = {\n    0: 'airplane',\n    1: 'automobile',\n    2: 'bird',\n    3: 'cat',\n    4: 'deer',\n    5: 'dog',\n    6: 'frog',\n    7: 'horse',\n    8: 'ship',\n    9: 'truck',\n}\n\nTRAIN_CLASSES_LIST = {\n    0: [],\n    1: [],\n    2: [],\n    3: [],\n    4: [],\n    5: [],\n    6: [],\n    7: [],\n    8: [],\n    9: [],\n}\nVAL_CLASSES_LIST = {\n    0: [],\n    1: [],\n    2: [],\n    3: [],\n    4: [],\n    5: [],\n    6: [],\n    7: [],\n    8: [],\n    9: [],\n}\nNUM_CLASSES = 10\nIMB_FACTOR = 0.02\nTRAIN_BATCH_SIZE = 128\nEVAL_BATCH_SIZE = 100\nMEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]\nTRAIN_TRANSFORM = transforms.Compose([\n#     transforms.Resize((40, 40)),\n#     transforms.RandomCrop(32),\n#     transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor(),\n#     transforms.Normalize(MEAN, STD),                       \n])\nVAL_TRANSFORM = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(MEAN, STD),                       \n])\ntraining_data = datasets.CIFAR10(\n    root='./',\n    train=True,\n    download=True,\n    transform=TRAIN_TRANSFORM,\n)\nprint(len(training_data))\ntest_data = datasets.CIFAR10(\n    root='./',\n    train=False,\n    download=True,\n    transform=VAL_TRANSFORM,\n)\nprint(len(test_data))\n","metadata":{"id":"4_sZlE9vwLcK","outputId":"20e0b51d-3343-48bd-cacc-8f525df39064","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_num_per_cls(percls_img_num, num_class, imb_factor):\n    img_num_per_cls = []\n    for i in range(10):\n        num = percls_img_num*((imb_factor)**(i/(10-1.0)))\n        img_num_per_cls.append(int(num))\n    return img_num_per_cls\n\ndef get_img_idx_per_cls(training_data, img_num_per_cls, classes_list):\n    for i in range(len(training_data)):\n        _, label = training_data[i]\n        if len(classes_list[label]) > img_num_per_cls[label]:\n            pass\n        else:\n            classes_list[label].append(i)\n    return classes_list","metadata":{"id":"5eKhD5IANWhy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CifarDataset(Dataset):\n    def __init__(self, dataset, img_per_cls, num_classes, transpose=False):\n        self.dataset = dataset\n        self.img_list = self.get_all_img_idx(img_per_cls, num_classes)\n        self.transpose = transpose\n        \n    \n    def __len__(self):\n        return len(self.img_list)\n\n    def __getitem__(self, idx):\n        img, label = self.dataset[self.img_list[idx]]\n        if self.transpose:\n            img = transforms.Compose([\n                transforms.ToPILImage(),\n                transforms.Resize((40, 40)),\n                transforms.RandomCrop(32),\n                transforms.RandomHorizontalFlip(p=0.5),\n                transforms.ToTensor(),\n                transforms.Normalize(MEAN, STD),\n            ])(img)\n        return img, label\n\n    def get_all_img_idx(self, img_per_cls, num_cls):\n        img_list = []\n        for i in range(num_cls):\n            img_list += img_per_cls[i]\n        return img_list","metadata":{"id":"AQ0S9604N7j3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_NUM_PER_CLS = get_img_num_per_cls(5000, NUM_CLASSES, IMB_FACTOR)\nTRAIN_CLASSES_LIST = get_img_idx_per_cls(training_data, IMG_NUM_PER_CLS, TRAIN_CLASSES_LIST)\ncifards_train = CifarDataset(training_data, TRAIN_CLASSES_LIST, NUM_CLASSES, transpose=True)\ntrain_dataloader = DataLoader(cifards_train, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n\nIMG_NUM_PER_CLS = get_img_num_per_cls(1000, NUM_CLASSES, IMB_FACTOR)\nVAL_CLASSES_LIST = get_img_idx_per_cls(test_data, IMG_NUM_PER_CLS, VAL_CLASSES_LIST)\ncifards_test = CifarDataset(test_data, VAL_CLASSES_LIST, NUM_CLASSES)\nval_dataloader = DataLoader(cifards_test, batch_size=EVAL_BATCH_SIZE)","metadata":{"id":"QG3uZN-eCE-n","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"test dataloader\"\"\"\n# for i, data in enumerate(train_dataloader):\n#     img, label = data\n#     figure = plt.figure(figsize=(8, 8))\n#     cols, rows = 3, 3\n#     for i in range(1, cols*rows+1):\n#         image = img[i].transpose(0, 2).transpose(0, 1)\n#         figure.add_subplot(rows, cols, i)\n#         plt.title(LABELS_MAP[int(label[i].numpy())])\n#         plt.axis('off')\n#         plt.imshow(image.squeeze())\n#     plt.show()\n#     break","metadata":{"id":"FStc-myFhuLE","outputId":"e0a9364f-a007-42d3-a71b-6ac2f15c121f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# learning schedule","metadata":{"id":"_oe7HznFicS5"}},{"cell_type":"code","source":"import torch.optim as optim\nfrom torch.optim.lr_scheduler import LambdaLR\nLEARNING_RATE_SCHEDULE = [5, 160, 180]\nLEARNING_RATE_MULTIPLIER = [1, 0.01, 0.0001]\nBASE_LEARNING = 0.1\nMOMENTUM = 0.9\nWEIGHT_DECAY = 2e-4\ndef learning_rate_schedule(current_epoch, base_learning_rate, lr_boundaries, lr_multiplier):\n    staged_lr = [base_learning_rate*x for x in lr_multiplier]\n    decay_rate = (base_learning_rate*current_epoch/lr_boundaries[0])\n    for st_lr, start_epoch in zip(staged_lr, lr_boundaries):\n        decay_rate = torch.where(current_epoch<start_epoch, decay_rate, st_lr)\n    \n    return decay_rate\n\ndef Cos_warmup(optimizer, epoch_warmup, lr_boundaries, lr_multiplier, num_cycles=0.5, last_epoch=-1):\n    def lr_lambda(current_epoch):\n        base_learning_rate=1\n        staged_lr = [base_learning_rate*x for x in lr_multiplier]\n        decay_rate = (base_learning_rate*current_epoch/lr_boundaries[0])\n        for st_lr, start_epoch in zip(staged_lr, lr_boundaries):\n            if current_epoch<start_epoch:\n                decay_rate = decay_rate\n            else:\n                decay_rate = st_lr\n        return max(0.0, decay_rate)\n    return LambdaLR(optimizer, lr_lambda, last_epoch)\n\ndef chose_optim(loss_type, model):\n    if loss_type == 'softmax':\n        optimizer = optim.SGD(\n            params=model.parameters(),\n            lr=BASE_LEARNING,\n            momentum=MOMENTUM,\n            weight_decay=WEIGHT_DECAY\n        )\n    elif loss_type == 'sigmoid' or loss_type == 'focal':\n        # 最后一层的bias不加入weight decay\n        all_parameters = model.parameters()\n        weight_parameters = []\n        for pname, p in model.named_parameters():\n            if 'fully_connected.bias' not in pname:\n                weight_parameters.append(p)\n        weight_parameters_id = list(map(id, weight_parameters))\n        other_parameters = list(filter(lambda p: id(p) not in weight_parameters_id, all_parameters))\n        optimizer = optim.SGD(\n            [\n            {'params': other_parameters},\n            {'params': weight_parameters, 'weight_decay': WEIGHT_DECAY}\n            ],\n            lr=BASE_LEARNING,\n            momentum=MOMENTUM,\n        )\n#     scheduler = optim.lr_scheduler.MultiStepLR(\n#         optimizer=optimizer,\n#         milestones=LEARNING_RATE_SCHEDULE,\n#         gamma=0.01\n#     )\n    cosWarmUp = Cos_warmup(\n            optimizer,\n            epoch_warmup=5,\n            lr_boundaries=[5, 160, 180],\n            lr_multiplier=[1, 0.1, 0.0001],\n        )\n    return optimizer, cosWarmUp","metadata":{"id":"R_LlHfXPigQ6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"util\"\"\"\nimport numpy as np\nclass AverageMeter(object):\n    def __init__(self, name, fmt=':f'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val*n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n        return fmtstr.format(**self.__dict__)\n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\nimport os\ndef save_model(model, save_dir, loss_type):\n    save_path = os.path.join(save_dir, loss_type+'.pth')\n    torch.save(model.state_dict(), save_path)\n    print('saved weights to : '+str(save_path))","metadata":{"id":"uVeOV0M4twzL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# training","metadata":{"id":"UKTC66qv-3Cl"}},{"cell_type":"code","source":"TRAIN_EPOCH = 200\nEVAL_EPOCHS = 5\nBETA = 0.9999\nSAVE_DIR = './'\nimport numpy as np\ndef get_weight(beta, img_num_per_class):\n    effective_num = 1.0 - np.power(beta, img_num_per_class)\n    weight = (1. - beta) / np.array(effective_num)\n    weight = weight / np.sum(weight) * NUM_CLASSES \n    return weight\n\nWEIGHT = get_weight(BETA, IMG_NUM_PER_CLS)","metadata":{"id":"UL0vZELv-6Ek","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_weight4training(org_weight, one_hot_label, num_classes):\n    weights = torch.from_numpy(org_weight).to(torch.float32).to(DEVICE)\n    weights = torch.unsqueeze(weights, 0)\n    weights = torch.tile(weights, [one_hot_label.shape[0], 1])*one_hot_label\n    weights = torch.sum(weights, 1)\n    weights = torch.unsqueeze(weights, 1)\n    weights = torch.tile(weights, [1, NUM_CLASSES])\n    return weights\n\ndef train_step(model, train_dataloader, loss_type, optimizer, scheduler):\n    model.train()\n    losses = AverageMeter('Loss', ':.4e')\n    train_top1 = AverageMeter('TrainAcc@1', ':6.2f')\n    for index, data in enumerate(train_dataloader):\n        img, label = data\n        img = img.to(DEVICE)\n        label = label.to(DEVICE)\n        logits = model(img)\n        if loss_type == 'softmax':\n            probabilities = F.softmax(logits, dim=-1)\n        elif loss_type == 'sigmoid' or loss_type == 'focal':\n            probabilities = torch.sigmoid(logits)\n        one_hot_labels = F.one_hot(label, num_classes=NUM_CLASSES)\n        wghs = compute_weight4training(WEIGHT, one_hot_labels, NUM_CLASSES)\n\n        if loss_type == 'softmax':\n            loss_fn = nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHT).to(torch.float32)).to(DEVICE)\n            loss = loss_fn(logits, label)\n        elif loss_type == 'sigmoid':\n            loss = focal_loss(one_hot_labels, logits, None, None, loss_type)*wghs\n            loss = torch.sum(loss)/torch.sum(one_hot_labels)\n        elif loss_type == 'focal':\n            loss = focal_loss(one_hot_labels, logits, wghs, GAMMA, loss_type)\n\n        prec1, = accuracy(probabilities, label, topk=(1,))\n        n = img.size(0)\n        losses.update(loss.item(), n)\n        train_top1.update(prec1.item(), n)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # print(f'[epoch: {epoch}][EPOCH: {TRAIN_EPOCH}]: [train loss: {losses.avg}]/[train acc: {train_top1.avg}]')\n    scheduler.step()\n    return losses.avg, train_top1.avg, index\n\ndef test_step(model, test_dataloader, loss_type):\n    val_top1 = AverageMeter('ValAcc@1', ':6.2f')\n    model.eval()\n    for index, data in enumerate(test_dataloader):\n        img, label = data\n        img = img.to(DEVICE)\n        label = label.to(DEVICE)\n        logits = model(img)\n        if loss_type == 'softmax':\n            probabilities = F.softmax(logits, dim=-1)\n        elif loss_type == 'sigmoid' or loss_type == 'focal':\n            probabilities = torch.sigmoid(logits)\n        prec1, = accuracy(probabilities, label, topk=(1,))\n        n = img.size(0)\n        val_top1.update(prec1.item(), n)\n    return val_top1.avg\n    # print(f'[testing ...]: [test acc: {val_top1.avg}]')","metadata":{"id":"MpTOrCdQV-Sj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_weight4training(org_weight, one_hot_label, num_classes):\n    weights = torch.from_numpy(org_weight).to(torch.float32).to(DEVICE)\n    weights = torch.unsqueeze(weights, 0)\n    weights = torch.tile(weights, [one_hot_label.shape[0], 1])*one_hot_label\n    weights = torch.sum(weights, 1)\n    weights = torch.unsqueeze(weights, 1)\n    weights = torch.tile(weights, [1, NUM_CLASSES])\n    return weights\n\n# cifarmodel=cifarModel( \n#         in_channels=3,\n#         num_layers=NUM_LAYERS, \n#         is_training=True, \n#         batch_norm_decay=0.9, \n#         batch_norm_epsilon=1e-5,\n#         version=RESNET_VERSION,\n#         num_classes=10, \n#         loss_type=LOSS_TYPE,\n#     ).to(DEVICE)\n\n\"\"\"===================there are three stage about training======================\"\"\"\n\"\"\"stage1:\"\"\"\nLOSS_TYPE = 'softmax'\nBEST_ACC = 0\ncifarmodel=cifarModel( \n        in_channels=3,\n        num_layers=NUM_LAYERS, \n        is_training=True, \n        batch_norm_decay=0.9, \n        batch_norm_epsilon=1e-5,\n        version=RESNET_VERSION,\n        num_classes=10, \n        loss_type=LOSS_TYPE,\n    ).to(DEVICE)\noptim1, sche1 = chose_optim(LOSS_TYPE, cifarmodel)\nfor epoch in range(TRAIN_EPOCH):\n    loss, train_top1, index = train_step(cifarmodel, train_dataloader, LOSS_TYPE, optim1, sche1)\n    if epoch % 5 == 0:\n        print('stage 1:[step: %.5d]'%(index*(epoch+1))+' [epoch: %.3d]'%(epoch)+'[EPOCH: %.3d]:'%(TRAIN_EPOCH)+' [train loss: %.2f]'%(loss)+'/[train acc: %.2f]'%(train_top1))\n    if epoch % EVAL_EPOCHS == 0:\n        val_top1 = test_step(cifarmodel, val_dataloader, LOSS_TYPE)\n        print('[testing ...]: [test acc: %2.2f]'%(val_top1))\n        if val_top1>BEST_ACC:\n            save_model(cifarmodel, SAVE_DIR, LOSS_TYPE)\n            BEST_ACC=val_top1\n\n\"\"\"stage2:\"\"\"\nLOSS_TYPE = 'sigmoid'\nBEST_ACC = 0\ncifarmodel=cifarModel( \n        in_channels=3,\n        num_layers=NUM_LAYERS, \n        is_training=True, \n        batch_norm_decay=0.9, \n        batch_norm_epsilon=1e-5,\n        version=RESNET_VERSION,\n        num_classes=10, \n        loss_type=LOSS_TYPE,\n    ).to(DEVICE)\n\noptim2, sche2 = chose_optim(LOSS_TYPE, cifarmodel)\nfor epoch in range(TRAIN_EPOCH):\n    loss, train_top1, index = train_step(cifarmodel, train_dataloader, LOSS_TYPE, optim2, sche2)\n    if epoch % 5 == 0:\n        print('stage 2: [step: %.5d]'%(index*(epoch+1))+'[epoch: %.3d]'%(epoch)+'[EPOCH: %.3d]:'%(TRAIN_EPOCH)+' [train loss: %.2f]'%(loss)+'/[train acc: %.2f]'%(train_top1))\n    if epoch % EVAL_EPOCHS == 0:\n        val_top1 = test_step(cifarmodel, val_dataloader, LOSS_TYPE)\n        print('[testing ...]: [test acc: %2.2f]'%(val_top1))\n        if val_top1>BEST_ACC:\n            save_model(cifarmodel, SAVE_DIR, LOSS_TYPE)\n            BEST_ACC=val_top1\n\n\"\"\"stage3:\"\"\"\nLOSS_TYPE = 'focal'\nBEST_ACC = 0\ncifarmodel=cifarModel( \n        in_channels=3,\n        num_layers=NUM_LAYERS, \n        is_training=True, \n        batch_norm_decay=0.9, \n        batch_norm_epsilon=1e-5,\n        version=RESNET_VERSION,\n        num_classes=10, \n        loss_type=LOSS_TYPE,\n    ).to(DEVICE)\n\noptim3, sche3 = chose_optim(LOSS_TYPE, cifarmodel)\nfor epoch in range(TRAIN_EPOCH):\n    loss, train_top1, index = train_step(cifarmodel, train_dataloader, LOSS_TYPE, optim3, sche3)\n    if epoch % 5 == 0:\n        print('stage 3: [step: %.5d]'%(index*(epoch+1))+'[epoch: %.3d]'%(epoch)+'[EPOCH: %.3d]:'%(TRAIN_EPOCH)+' [train loss: %.2f]'%(loss)+'/[train acc: %.2f]'%(train_top1))\n    if epoch % EVAL_EPOCHS == 0:\n        val_top1 = test_step(cifarmodel, val_dataloader, LOSS_TYPE)\n        print('[testing ...]: [test acc: %2.2f]'%(val_top1))\n        if val_top1>BEST_ACC:\n            save_model(cifarmodel, SAVE_DIR, LOSS_TYPE)\n            BEST_ACC=val_top1","metadata":{"id":"bvxFaUwWKQo5","outputId":"b2434137-a9dd-45d9-8012-1ebf9ea05d26","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}