{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"about data long-tailed/data imbalance\n\nreference：https://github.com/richardaecn/class-balanced-loss\n\npaper：Class-Balanced Loss Based on Effective Number of Samples\n\n\npytorch==1.9.0\n\n\nyou can only run this code without any other prepare,some important part have test code to compare with offical tf version\n\n\nMost parameters are the same with tf's version, but this version's acc is slightly higher than tf, may beceuse of some random. \n\n\nIf there is any problem, i will try to modify in time\n\ndataset: cifar10 with imbalanced distribution","metadata":{"id":"CbwYbRum9_ur"}},{"cell_type":"code","source":"!pip3 install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(torch.__version__)","metadata":{"id":"F3lh2xqy6XMO","execution":{"iopub.status.busy":"2021-08-31T01:13:14.519229Z","iopub.execute_input":"2021-08-31T01:13:14.519619Z","iopub.status.idle":"2021-08-31T01:13:20.973660Z","shell.execute_reply.started":"2021-08-31T01:13:14.519536Z","shell.execute_reply":"2021-08-31T01:13:20.972679Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Looking in links: https://download.pytorch.org/whl/torch_stable.html\nRequirement already satisfied: torch==1.9.0+cu102 in /opt/conda/lib/python3.7/site-packages (1.9.0+cu102)\nRequirement already satisfied: torchvision==0.10.0+cu102 in /opt/conda/lib/python3.7/site-packages (0.10.0+cu102)\nRequirement already satisfied: torchaudio===0.9.0 in /opt/conda/lib/python3.7/site-packages (0.9.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0+cu102) (3.7.4.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.10.0+cu102) (1.19.5)\nRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.10.0+cu102) (8.2.0)\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n1.9.0+cu102\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model\n","metadata":{"id":"1del5JKqJSdz"}},{"cell_type":"code","source":"NUM_LAYERS = 32\nRESNET_VERSION = 'v1'\nBATCH_NORM_EPSILON = 1e-5\nBATCH_NORM_DECAY = 0.9\nLOSS_TYPE = 'softmax'\nclass Residual_v1(nn.Module):\n    def __init__(self, in_filter, out_filter, stride, activate_before_residual=False):\n        super(Residual_v1, self).__init__()\n        if stride == 1:\n            self.padding = 'same'\n        else:\n            self.padding = 'valid'\n        \n        self.kernel_size = 3\n        self.in_filter = in_filter\n        self.out_filter = out_filter\n        self.conv1 = nn.Conv2d(\n            in_channels=in_filter,\n            out_channels=out_filter,\n            kernel_size=3,\n            stride=stride,\n            padding=self.padding,\n            bias=False,\n        )\n        self.bn1 = nn.BatchNorm2d(num_features=out_filter)\n        self.relu1 = nn.ReLU()\n\n        self.conv2 = nn.Conv2d(\n            in_channels=out_filter,\n            out_channels=out_filter,\n            kernel_size=3,\n            stride=1,\n            padding='same',\n            bias=False,\n        )\n        self.bn2 = nn.BatchNorm2d(num_features=out_filter)\n\n        if in_filter != out_filter:\n            self.avg_pool = nn.AvgPool2d(kernel_size=(stride, stride), stride=stride, ceil_mode=True)\n        self.relu2 = nn.ReLU()\n\n    def forward(self, x):\n        orig_x = x\n        if self.padding == 'valid':\n            pad = self.kernel_size - 1\n            pad_beg = pad // 2\n            pad_end = pad - pad_beg\n            p2d=(pad_beg, pad_end, pad_end, pad_beg, )\n            x=F.pad(x, p2d, 'constant', 0)\n            x = self.conv1(x)\n        else:\n            x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu1(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n        if self.in_filter != self.out_filter:\n            orig_x = self.avg_pool(orig_x)\n            pad = (self.out_filter-self.in_filter) // 2\n            p2d = (0, 0, 0, 0, pad, pad)\n            orig_x = F.pad(orig_x, p2d, 'constant', 0)\n\n        x = self.relu2(torch.add(x, orig_x))\n        return x","metadata":{"id":"SdMqrscuSTi0","execution":{"iopub.status.busy":"2021-08-31T01:13:24.773590Z","iopub.execute_input":"2021-08-31T01:13:24.773926Z","iopub.status.idle":"2021-08-31T01:13:24.788153Z","shell.execute_reply.started":"2021-08-31T01:13:24.773895Z","shell.execute_reply":"2021-08-31T01:13:24.787147Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\"\"\"test pad\"\"\"\n# import tensorflow as tf\n# import numpy as np\n# import torch.nn.functional as F\n# in_filter=4\n# out_filter=8\n# pad=(out_filter-in_filter)//2\n\n# img = np.random.normal(size=(2, 4, 24, 24))\n# a=tf.convert_to_tensor(img)\n# x=tf.pad(a, [[0, 0], [pad, pad], [0, 0], [0, 0]])\n# print(x.shape)\n# print(x[0, :, 1, 1])\n# print('----------------')\n\n# b=torch.from_numpy(img)\n# p2d=(0, 0, 0, 0, pad, pad)\n# out=F.pad(b, p2d, 'constant', 0)\n# print(out.shape)\n# print(out[0, :, 1, 1])\n\n\"\"\"test Resdual_v1\"\"\"\nimg = torch.randn(size=(2, 4, 224, 224))\nlayer = Residual_v1(\n    in_filter=4,\n    out_filter=8,\n    stride=2\n)\nc=layer(img)\nprint(c.shape)","metadata":{"id":"YUDs-VCL3k4c","outputId":"df442fa0-8ec0-4d47-9b3f-ab07c11ff4e4","execution":{"iopub.status.busy":"2021-08-31T01:13:26.684450Z","iopub.execute_input":"2021-08-31T01:13:26.684773Z","iopub.status.idle":"2021-08-31T01:13:26.711937Z","shell.execute_reply.started":"2021-08-31T01:13:26.684740Z","shell.execute_reply":"2021-08-31T01:13:26.710858Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"torch.Size([2, 8, 112, 112])\n","output_type":"stream"}]},{"cell_type":"code","source":"class Residual_v2(nn.Module):\n    def __init__(self, in_filter, out_filter, stride, activate_before_residual=False):\n        super(Residual_v2, self).__init__()\n        self.in_filter = in_filter\n        self.out_filter = out_filter\n        self.activate_before_residual = activate_before_residual\n        if stride == 1:\n            self.padding = 'same'\n        else:\n            self.padding = 1\n\n        self.bn1 = nn.BatchNorm2d(num_features=in_filter)\n        self.relu1 = nn.ReLU()\n        self.conv1 = nn.Conv2d(\n            in_channels=in_filter,\n            out_channels=out_filter,\n            kernel_size=3,\n            stride=stride,\n            padding=self.padding,\n            bias=False\n        )\n\n        self.bn2 = nn.BatchNorm2d(num_features=out_filter)\n        self.relu2 = nn.ReLU()\n        self.conv2 = nn.Conv2d(\n            in_channels=out_filter,\n            out_channels=out_filter,\n            kernel_size=3,\n            stride=1,\n            padding='same',\n            bias=False\n        )\n\n        if in_filter != out_filter:\n            self.avg_pool = nn.AvgPool2d(kernel_size=(stride, stride), stride=stride, ceil_mode=True)\n\n    def forward(self, x):\n        if self.activate_before_residual:\n            x = self.bn1(x)\n            x = self.relu(x)\n            orig_x = x\n        else:\n            orig_x = x\n            x = self.bn1(x)\n            x = self.relu1(x)\n\n        x = self.conv1(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n        x = self.conv2(x)\n\n        if self.in_filter != self.out_filter:\n            orig_x = self.avg_pool(orig_x)\n            pad = (self.out_filter-self.in_filter) // 2\n            p2d = (0, 0, 0, 0, pad, pad)\n            orig_x = F.pad(orig_x, p2d, 'constant', 0)\n        x = torch.add(x, orig_x)\n        return x\n","metadata":{"id":"94ZGAZvdZGoq","execution":{"iopub.status.busy":"2021-08-31T01:13:28.412157Z","iopub.execute_input":"2021-08-31T01:13:28.412482Z","iopub.status.idle":"2021-08-31T01:13:28.424138Z","shell.execute_reply.started":"2021-08-31T01:13:28.412452Z","shell.execute_reply":"2021-08-31T01:13:28.423087Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\"\"\"test Residual_v2\"\"\"\nimg = torch.randn(size=(2, 4, 224, 224))\nlayer = Residual_v2(\n    in_filter=4,\n    out_filter=8,\n    stride=1\n)\nc=layer(img)\nprint(c.shape)","metadata":{"id":"d3o0v8b2A7PY","outputId":"658f27f8-2f6b-47e3-cfaa-9c338c1c316b","execution":{"iopub.status.busy":"2021-08-31T01:13:29.557783Z","iopub.execute_input":"2021-08-31T01:13:29.558172Z","iopub.status.idle":"2021-08-31T01:13:29.601036Z","shell.execute_reply.started":"2021-08-31T01:13:29.558142Z","shell.execute_reply":"2021-08-31T01:13:29.600114Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"torch.Size([2, 8, 224, 224])\n","output_type":"stream"}]},{"cell_type":"code","source":"class Bottlenet_residual_v2(nn.Module):\n    def __init__(self, in_filter, out_filter, stride, activate_before_residual=False):\n        super(Bottlenet_residual_v2, self).__init__()\n        self.in_filter = in_filter\n        self.out_filter = out_filter\n        self.activate_before_residual = activate_before_residual\n        self.bn1 = nn.BatchNorm2d(num_features=in_filter)\n        self.relu1 = nn.ReLU()\n        \n        self.conv1 = nn.Conv2d(\n            in_channels=in_filter,\n            out_channels=out_filter//4,\n            kernel_size=1,\n            stride=stride,\n            bias=False\n        )\n        \n        self.bn2 = nn.BatchNorm2d(num_features=out_filter//4)\n        self.relu2 = nn.ReLU()\n        self.conv2 = nn.Conv2d(\n            in_channels=out_filter//4,\n            out_channels=out_filter//4,\n            kernel_size=3,\n            stride=1,\n            padding='same',\n            bias=False\n        )\n\n        self.bn3 = nn.BatchNorm2d(num_features=out_filter//4)\n        self.relu3 = nn.ReLU()\n        self.conv3 = nn.Conv2d(\n            in_channels=out_filter//4,\n            out_channels=out_filter,\n            kernel_size=1,\n            stride=1,\n            bias=False\n        )\n\n        if in_filter != out_filter:\n            self.conv4 = nn.Conv2d(\n                in_channels=in_filter,\n                out_channels=out_filter,\n                kernel_size=1,\n                stride=stride,\n                bias=False\n            )\n\n    def forward(self, x):\n        if self.activate_before_residual:\n            x = self.bn1(x)\n            x = self.relu1(x)\n            orig_x = x\n        else:\n            orig_x = x\n            x = self.bn1(x)\n            x = self.relu1(x)\n        x = self.conv1(x)\n        \n        x = self.bn2(x)\n        x = self.relu2(x)\n        x = self.conv2(x)\n\n        x = self.bn3(x)\n        x = self.relu3(x)\n        x = self.conv3(x)\n        if self.in_filter != self.out_filter:\n            orig_x = self.conv4(orig_x)\n        \n        x = torch.add(x, orig_x)\n        return x","metadata":{"id":"51QKb3hSd2jz","execution":{"iopub.status.busy":"2021-08-31T01:13:31.482543Z","iopub.execute_input":"2021-08-31T01:13:31.482901Z","iopub.status.idle":"2021-08-31T01:13:31.495435Z","shell.execute_reply.started":"2021-08-31T01:13:31.482870Z","shell.execute_reply":"2021-08-31T01:13:31.494567Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\"\"\"test Bottlenet_residual_v2\"\"\"\nimg = torch.randn(size=(2, 4, 224, 224))\nlayer = Bottlenet_residual_v2(\n    in_filter=4,\n    out_filter=8,\n    stride=1\n)\nc=layer(img)\nprint(c.shape)","metadata":{"id":"b3BVz70-Dc0S","outputId":"96ceaca8-aaa6-4576-bbf9-479097516309","execution":{"iopub.status.busy":"2021-08-31T01:13:32.652978Z","iopub.execute_input":"2021-08-31T01:13:32.653316Z","iopub.status.idle":"2021-08-31T01:13:32.673556Z","shell.execute_reply.started":"2021-08-31T01:13:32.653284Z","shell.execute_reply":"2021-08-31T01:13:32.672574Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"torch.Size([2, 8, 224, 224])\n","output_type":"stream"}]},{"cell_type":"code","source":"class cifarModel(nn.Module):\n    def __init__(\n        self, \n        in_channels,\n        num_layers, \n        is_training, \n        batch_norm_decay, \n        batch_norm_epsilon,\n        version='v1',\n        num_classes=10, \n        loss_type='softmax',\n    ):\n        super(cifarModel, self).__init__()\n        self.n = (num_layers-2) // 6\n        self.filters = [16, 16, 32, 64]\n        self.strides = [1, 2, 2]\n        self.version = version\n        self.loss_type = loss_type\n        self.num_classes = num_classes\n\n        self.conv1 = nn.Conv2d(\n            in_channels=in_channels,\n            out_channels=16,\n            kernel_size=3,\n            stride=1,\n            padding='same',\n            bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(\n            num_features=16,\n            eps=batch_norm_epsilon,\n            momentum=1.-batch_norm_decay\n        )\n        self.relu1 = nn.ReLU()\n\n        if self.version == 'v1':\n            res_func = Residual_v1\n        elif self.version == 'v2':\n            res_func = Residual_v2\n        else:\n            res_func = Bottlenet_residual_v2\n\n        # make block\n        self.main_block_list = []\n        for i in range(3):\n            for j in range(self.n):\n                if j == 0:\n                    self.main_block_list.append(\n                        res_func(self.filters[i], self.filters[i+1], self.strides[i])\n                    )\n                else:\n                    self.main_block_list.append(\n                        res_func(self.filters[i+1], self.filters[i+1], 1)\n                    )\n        self.main_block = nn.ModuleList(self.main_block_list)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.flatten = nn.Flatten()\n        if self.loss_type == 'softmax':\n            self.fully_connected = nn.Linear(\n                in_features=self.filters[-1],\n                out_features=self.num_classes,\n            )\n\n        elif self.loss_type == 'sigmoid' or self.loss_type == 'focal':\n            self.fully_connected = nn.Linear(\n                in_features=self.filters[-1],\n                out_features=self.num_classes,\n            )\n            nn.init.constant_(self.fully_connected.bias, -torch.log(torch.tensor(self.num_classes-1).to(DEVICE).to(torch.float32)))\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu1(x)\n        for i in range(len(self.main_block_list)):\n            x = self.main_block[i](x)\n        x = self.avgpool(x)\n        x = self.flatten(x)\n        x = self.fully_connected(x)\n        return x\n        ","metadata":{"id":"XVOU4GDFli4D","execution":{"iopub.status.busy":"2021-08-31T01:13:50.478893Z","iopub.execute_input":"2021-08-31T01:13:50.479219Z","iopub.status.idle":"2021-08-31T01:13:50.495212Z","shell.execute_reply.started":"2021-08-31T01:13:50.479190Z","shell.execute_reply":"2021-08-31T01:13:50.493652Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"cifarmodel=cifarModel( \n        in_channels=3,\n        num_layers=NUM_LAYERS, \n        is_training=True, \n        batch_norm_decay=0.9, \n        batch_norm_epsilon=1e-5,\n        version=RESNET_VERSION,\n        num_classes=10, \n        loss_type=LOSS_TYPE,\n    ).to(DEVICE)\n\"\"\"test cifarModel\"\"\"\n# img=torch.randn(size=(2, 3, 224, 224)).to(DEVICE)\n# y=cifarmodel(img)\n# print(y)\n# print(y.shape)\n# print(cifarmodel.fully_connected.bias)\n# nn.init.constant_(cifarmodel.fully_connected.bias, -torch.log(torch.tensor(63).to(DEVICE).to(torch.float32)))\n# print(cifarmodel.fully_connected.bias)","metadata":{"id":"Z7UmY1SaVIsO","outputId":"f97c103b-1d08-4e17-e6b1-11f0a0bbe253","execution":{"iopub.status.busy":"2021-08-31T01:13:54.181051Z","iopub.execute_input":"2021-08-31T01:13:54.181376Z","iopub.status.idle":"2021-08-31T01:13:56.884992Z","shell.execute_reply.started":"2021-08-31T01:13:54.181346Z","shell.execute_reply":"2021-08-31T01:13:56.884128Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'test cifarModel'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Loss\n","metadata":{"id":"5jubBOB9dZUV"}},{"cell_type":"code","source":"GAMMA = 1.\ndef focal_loss(labels, logits, alpha, gamma, loss_type):\n    def sigmoid_cross_entropy_with_logits(label, logit):\n        return torch.maximum(logit, logit*0)-(logit*label)+torch.log(1+torch.exp(-torch.abs(logits)))\n\n    cross_entropy = sigmoid_cross_entropy_with_logits(labels, logits)\n    if loss_type == 'sigmoid':\n        return cross_entropy\n    else:\n        if gamma == 0.0:\n            modulator = 1.0\n        else:\n            x = gamma*torch.log1p(torch.exp(-1.0*logits))\n            modulator = torch.exp(-gamma*labels*logits-x)\n        loss = modulator*cross_entropy\n        weighted_loss = alpha*loss\n        focal_loss = torch.sum(weighted_loss)\n        focal_loss /= torch.sum(labels)\n\n        return focal_loss","metadata":{"id":"CjeAnNX9dY1w","execution":{"iopub.status.busy":"2021-08-31T01:14:00.467296Z","iopub.execute_input":"2021-08-31T01:14:00.467648Z","iopub.status.idle":"2021-08-31T01:14:00.474456Z","shell.execute_reply.started":"2021-08-31T01:14:00.467615Z","shell.execute_reply":"2021-08-31T01:14:00.473568Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\"\"\"test focal_loss\"\"\"\nimport tensorflow as tf\nimport numpy as np\n\ndef tf_focal_loss(labels, logits, alpha, gamma):\n    with tf.name_scope('focal_loss'):\n        logits = tf.cast(logits, dtype=tf.float32)\n        cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(\n            labels=labels, logits=logits)\n        if gamma == 0.0:\n            modulator = 1.0\n        else:\n            modulator = tf.exp(-gamma * labels * logits - gamma * tf.math.log1p(\n              tf.exp(-1.0 * logits)))\n        loss = modulator * cross_entropy\n        weighted_loss = alpha * loss\n        focal_loss = tf.reduce_sum(weighted_loss)\n        focal_loss /= tf.reduce_sum(labels)\n    return focal_loss\n\n# logits = np.random.normal(size=(2, 10))\n# labels = np.random.normal(size=(2, 10))\n# tf_logits = tf.cast(tf.convert_to_tensor(logits), tf.float32)\n# tf_labels = tf.cast(tf.convert_to_tensor(labels), tf.float32)\n# tf_loss = tf_focal_loss(tf_labels, tf_logits, 1., 1.)\n# print(tf_loss)\n# print('----------------')\n\n# pt_logits = torch.from_numpy(logits)\n# pt_labels = torch.from_numpy(labels)\n# pt_loss = focal_loss(pt_labels, pt_logits, 1., 1.)\n# print(pt_loss)","metadata":{"id":"_3_xgGn4ip-e","execution":{"iopub.status.busy":"2021-08-31T01:14:03.547927Z","iopub.execute_input":"2021-08-31T01:14:03.548253Z","iopub.status.idle":"2021-08-31T01:14:07.793921Z","shell.execute_reply.started":"2021-08-31T01:14:03.548222Z","shell.execute_reply":"2021-08-31T01:14:07.792996Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"Fn8hqYxKsO3B"}},{"cell_type":"code","source":"import torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torch\n\nLABELS_MAP = {\n    0: 'airplane',\n    1: 'automobile',\n    2: 'bird',\n    3: 'cat',\n    4: 'deer',\n    5: 'dog',\n    6: 'frog',\n    7: 'horse',\n    8: 'ship',\n    9: 'truck',\n}\n\nTRAIN_CLASSES_LIST = {\n    0: [],\n    1: [],\n    2: [],\n    3: [],\n    4: [],\n    5: [],\n    6: [],\n    7: [],\n    8: [],\n    9: [],\n}\nVAL_CLASSES_LIST = {\n    0: [],\n    1: [],\n    2: [],\n    3: [],\n    4: [],\n    5: [],\n    6: [],\n    7: [],\n    8: [],\n    9: [],\n}\nNUM_CLASSES = 10\nIMB_FACTOR = 0.02\nTRAIN_BATCH_SIZE = 128\nEVAL_BATCH_SIZE = 100\nMEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]\nTRAIN_TRANSFORM = transforms.Compose([\n#     transforms.Resize((40, 40)),\n#     transforms.RandomCrop(32),\n#     transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor(),\n#     transforms.Normalize(MEAN, STD),                       \n])\nVAL_TRANSFORM = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(MEAN, STD),                       \n])\ntraining_data = datasets.CIFAR10(\n    root='./',\n    train=True,\n    download=True,\n    transform=TRAIN_TRANSFORM,\n)\nprint(len(training_data))\ntest_data = datasets.CIFAR10(\n    root='./',\n    train=False,\n    download=True,\n    transform=VAL_TRANSFORM,\n)\nprint(len(test_data))\n","metadata":{"id":"4_sZlE9vwLcK","outputId":"20e0b51d-3343-48bd-cacc-8f525df39064","execution":{"iopub.status.busy":"2021-08-31T01:14:07.795393Z","iopub.execute_input":"2021-08-31T01:14:07.795713Z","iopub.status.idle":"2021-08-31T01:14:18.128029Z","shell.execute_reply.started":"2021-08-31T01:14:07.795679Z","shell.execute_reply":"2021-08-31T01:14:18.126478Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/170498071 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bed3bdd281744a82a246f2f6ed25ffc4"}},"metadata":{}},{"name":"stdout","text":"Extracting ./cifar-10-python.tar.gz to ./\n50000\nFiles already downloaded and verified\n10000\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_img_num_per_cls(percls_img_num, num_class, imb_factor):\n    img_num_per_cls = []\n    for i in range(10):\n        num = percls_img_num*((imb_factor)**(i/(10-1.0)))\n        img_num_per_cls.append(int(num))\n    return img_num_per_cls\n\ndef get_img_idx_per_cls(training_data, img_num_per_cls, classes_list):\n    for i in range(len(training_data)):\n        _, label = training_data[i]\n        if len(classes_list[label]) > img_num_per_cls[label]:\n            pass\n        else:\n            classes_list[label].append(i)\n    return classes_list","metadata":{"id":"5eKhD5IANWhy","execution":{"iopub.status.busy":"2021-08-31T01:14:18.793550Z","iopub.execute_input":"2021-08-31T01:14:18.793884Z","iopub.status.idle":"2021-08-31T01:14:18.800475Z","shell.execute_reply.started":"2021-08-31T01:14:18.793853Z","shell.execute_reply":"2021-08-31T01:14:18.799429Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class CifarDataset(Dataset):\n    def __init__(self, dataset, img_per_cls, num_classes, transpose=False):\n        self.dataset = dataset\n        self.img_list = self.get_all_img_idx(img_per_cls, num_classes)\n        self.transpose = transpose\n        \n    \n    def __len__(self):\n        return len(self.img_list)\n\n    def __getitem__(self, idx):\n        img, label = self.dataset[self.img_list[idx]]\n        if self.transpose:\n            img = transforms.Compose([\n                transforms.ToPILImage(),\n                transforms.Resize((40, 40)),\n                transforms.RandomCrop(32),\n                transforms.RandomHorizontalFlip(p=0.5),\n                transforms.ToTensor(),\n                transforms.Normalize(MEAN, STD),\n            ])(img)\n        return img, label\n\n    def get_all_img_idx(self, img_per_cls, num_cls):\n        img_list = []\n        for i in range(num_cls):\n            img_list += img_per_cls[i]\n        return img_list","metadata":{"id":"AQ0S9604N7j3","execution":{"iopub.status.busy":"2021-08-31T01:14:20.318261Z","iopub.execute_input":"2021-08-31T01:14:20.318610Z","iopub.status.idle":"2021-08-31T01:14:20.326737Z","shell.execute_reply.started":"2021-08-31T01:14:20.318578Z","shell.execute_reply":"2021-08-31T01:14:20.325767Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"IMG_NUM_PER_CLS = get_img_num_per_cls(5000, NUM_CLASSES, IMB_FACTOR)\nTRAIN_CLASSES_LIST = get_img_idx_per_cls(training_data, IMG_NUM_PER_CLS, TRAIN_CLASSES_LIST)\ncifards_train = CifarDataset(training_data, TRAIN_CLASSES_LIST, NUM_CLASSES, transpose=True)\ntrain_dataloader = DataLoader(cifards_train, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n\nIMG_NUM_PER_CLS = get_img_num_per_cls(1000, NUM_CLASSES, IMB_FACTOR)\nVAL_CLASSES_LIST = get_img_idx_per_cls(test_data, IMG_NUM_PER_CLS, VAL_CLASSES_LIST)\ncifards_test = CifarDataset(test_data, VAL_CLASSES_LIST, NUM_CLASSES)\nval_dataloader = DataLoader(cifards_test, batch_size=EVAL_BATCH_SIZE)","metadata":{"id":"QG3uZN-eCE-n","execution":{"iopub.status.busy":"2021-08-31T01:14:22.293039Z","iopub.execute_input":"2021-08-31T01:14:22.293370Z","iopub.status.idle":"2021-08-31T01:14:28.761566Z","shell.execute_reply.started":"2021-08-31T01:14:22.293341Z","shell.execute_reply":"2021-08-31T01:14:28.760729Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\"\"\"test dataloader\"\"\"\n# for i, data in enumerate(train_dataloader):\n#     img, label = data\n#     figure = plt.figure(figsize=(8, 8))\n#     cols, rows = 3, 3\n#     for i in range(1, cols*rows+1):\n#         image = img[i].transpose(0, 2).transpose(0, 1)\n#         figure.add_subplot(rows, cols, i)\n#         plt.title(LABELS_MAP[int(label[i].numpy())])\n#         plt.axis('off')\n#         plt.imshow(image.squeeze())\n#     plt.show()\n#     break","metadata":{"id":"FStc-myFhuLE","outputId":"e0a9364f-a007-42d3-a71b-6ac2f15c121f","execution":{"iopub.status.busy":"2021-08-31T01:14:28.762997Z","iopub.execute_input":"2021-08-31T01:14:28.763362Z","iopub.status.idle":"2021-08-31T01:14:28.769338Z","shell.execute_reply.started":"2021-08-31T01:14:28.763323Z","shell.execute_reply":"2021-08-31T01:14:28.768318Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'test dataloader'"},"metadata":{}}]},{"cell_type":"markdown","source":"# learning schedule","metadata":{"id":"_oe7HznFicS5"}},{"cell_type":"code","source":"import torch.optim as optim\nfrom torch.optim.lr_scheduler import LambdaLR\nLEARNING_RATE_SCHEDULE = [5, 160, 180]\nLEARNING_RATE_MULTIPLIER = [1, 0.01, 0.0001]\nBASE_LEARNING = 0.1\nMOMENTUM = 0.9\nWEIGHT_DECAY = 2e-4\ndef learning_rate_schedule(current_epoch, base_learning_rate, lr_boundaries, lr_multiplier):\n    staged_lr = [base_learning_rate*x for x in lr_multiplier]\n    decay_rate = (base_learning_rate*current_epoch/lr_boundaries[0])\n    for st_lr, start_epoch in zip(staged_lr, lr_boundaries):\n        decay_rate = torch.where(current_epoch<start_epoch, decay_rate, st_lr)\n    \n    return decay_rate\n\ndef Cos_warmup(optimizer, epoch_warmup, lr_boundaries, lr_multiplier, num_cycles=0.5, last_epoch=-1):\n    def lr_lambda(current_epoch):\n        base_learning_rate=1\n        staged_lr = [base_learning_rate*x for x in lr_multiplier]\n        decay_rate = (base_learning_rate*current_epoch/lr_boundaries[0])\n        for st_lr, start_epoch in zip(staged_lr, lr_boundaries):\n            if current_epoch<start_epoch:\n                decay_rate = decay_rate\n            else:\n                decay_rate = st_lr\n        return max(0.0, decay_rate)\n    return LambdaLR(optimizer, lr_lambda, last_epoch)\n\ndef chose_optim(loss_type, model):\n    if loss_type == 'softmax':\n        optimizer = optim.SGD(\n            params=model.parameters(),\n            lr=BASE_LEARNING,\n            momentum=MOMENTUM,\n            weight_decay=WEIGHT_DECAY\n        )\n    elif loss_type == 'sigmoid' or loss_type == 'focal':\n        # 最后一层的bias不加入weight decay\n        all_parameters = model.parameters()\n        weight_parameters = []\n        for pname, p in model.named_parameters():\n            if 'fully_connected.bias' not in pname:\n                weight_parameters.append(p)\n        weight_parameters_id = list(map(id, weight_parameters))\n        other_parameters = list(filter(lambda p: id(p) not in weight_parameters_id, all_parameters))\n        optimizer = optim.SGD(\n            [\n            {'params': other_parameters},\n            {'params': weight_parameters, 'weight_decay': WEIGHT_DECAY}\n            ],\n            lr=BASE_LEARNING,\n            momentum=MOMENTUM,\n        )\n#     scheduler = optim.lr_scheduler.MultiStepLR(\n#         optimizer=optimizer,\n#         milestones=LEARNING_RATE_SCHEDULE,\n#         gamma=0.01\n#     )\n    cosWarmUp = Cos_warmup(\n            optimizer,\n            epoch_warmup=5,\n            lr_boundaries=[5, 160, 180],\n            lr_multiplier=[1, 0.1, 0.0001],\n        )\n    return optimizer, cosWarmUp","metadata":{"id":"R_LlHfXPigQ6","execution":{"iopub.status.busy":"2021-08-31T01:21:19.958374Z","iopub.execute_input":"2021-08-31T01:21:19.958697Z","iopub.status.idle":"2021-08-31T01:21:19.973865Z","shell.execute_reply.started":"2021-08-31T01:21:19.958666Z","shell.execute_reply":"2021-08-31T01:21:19.972887Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"\"\"\"util\"\"\"\nimport numpy as np\nclass AverageMeter(object):\n    def __init__(self, name, fmt=':f'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val*n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n        return fmtstr.format(**self.__dict__)\n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\nimport os\ndef save_model(model, save_dir, loss_type):\n    save_path = os.path.join(save_dir, loss_type+'.pth')\n    torch.save(model.state_dict(), save_path)\n    print('saved weights to : '+str(save_path))","metadata":{"id":"uVeOV0M4twzL","execution":{"iopub.status.busy":"2021-08-31T01:21:22.063182Z","iopub.execute_input":"2021-08-31T01:21:22.063516Z","iopub.status.idle":"2021-08-31T01:21:22.073785Z","shell.execute_reply.started":"2021-08-31T01:21:22.063486Z","shell.execute_reply":"2021-08-31T01:21:22.072783Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# training","metadata":{"id":"UKTC66qv-3Cl"}},{"cell_type":"code","source":"TRAIN_EPOCH = 200\nEVAL_EPOCHS = 5\nBETA = 0.9999\nSAVE_DIR = './weights'\nimport numpy as np\ndef get_weight(beta, img_num_per_class):\n    effective_num = 1.0 - np.power(beta, img_num_per_class)\n    weight = (1. - beta) / np.array(effective_num)\n    weight = weight / np.sum(weight) * NUM_CLASSES \n    return weight\n\nWEIGHT = get_weight(BETA, IMG_NUM_PER_CLS)","metadata":{"id":"UL0vZELv-6Ek","execution":{"iopub.status.busy":"2021-08-31T01:21:26.070674Z","iopub.execute_input":"2021-08-31T01:21:26.071135Z","iopub.status.idle":"2021-08-31T01:21:26.082314Z","shell.execute_reply.started":"2021-08-31T01:21:26.071095Z","shell.execute_reply":"2021-08-31T01:21:26.081398Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def compute_weight4training(org_weight, one_hot_label, num_classes):\n    weights = torch.from_numpy(org_weight).to(torch.float32).to(DEVICE)\n    weights = torch.unsqueeze(weights, 0)\n    weights = torch.tile(weights, [one_hot_label.shape[0], 1])*one_hot_label\n    weights = torch.sum(weights, 1)\n    weights = torch.unsqueeze(weights, 1)\n    weights = torch.tile(weights, [1, NUM_CLASSES])\n    return weights\n\ndef train_step(model, train_dataloader, loss_type, optimizer, scheduler):\n    model.train()\n    losses = AverageMeter('Loss', ':.4e')\n    train_top1 = AverageMeter('TrainAcc@1', ':6.2f')\n    for index, data in enumerate(train_dataloader):\n        img, label = data\n        img = img.to(DEVICE)\n        label = label.to(DEVICE)\n        logits = model(img)\n        if loss_type == 'softmax':\n            probabilities = F.softmax(logits, dim=-1)\n        elif loss_type == 'sigmoid' or loss_type == 'focal':\n            probabilities = torch.sigmoid(logits)\n        one_hot_labels = F.one_hot(label, num_classes=NUM_CLASSES)\n        wghs = compute_weight4training(WEIGHT, one_hot_labels, NUM_CLASSES)\n\n        if loss_type == 'softmax':\n            loss_fn = nn.CrossEntropyLoss(weight=torch.from_numpy(WEIGHT).to(torch.float32)).to(DEVICE)\n            loss = loss_fn(logits, label)\n        elif loss_type == 'sigmoid':\n            loss = focal_loss(one_hot_labels, logits, None, None, loss_type)*wghs\n            loss = torch.sum(loss)/torch.sum(one_hot_labels)\n        elif loss_type == 'focal':\n            loss = focal_loss(one_hot_labels, logits, wghs, GAMMA, loss_type)\n\n        prec1, = accuracy(probabilities, label, topk=(1,))\n        n = img.size(0)\n        losses.update(loss.item(), n)\n        train_top1.update(prec1.item(), n)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    # print(f'[epoch: {epoch}][EPOCH: {TRAIN_EPOCH}]: [train loss: {losses.avg}]/[train acc: {train_top1.avg}]')\n    scheduler.step()\n    return losses.avg, train_top1.avg, index\n\ndef test_step(model, test_dataloader, loss_type):\n    val_top1 = AverageMeter('ValAcc@1', ':6.2f')\n    model.eval()\n    for index, data in enumerate(test_dataloader):\n        img, label = data\n        img = img.to(DEVICE)\n        label = label.to(DEVICE)\n        logits = model(img)\n        if loss_type == 'softmax':\n            probabilities = F.softmax(logits, dim=-1)\n        elif loss_type == 'sigmoid' or loss_type == 'focal':\n            probabilities = torch.sigmoid(logits)\n        prec1, = accuracy(probabilities, label, topk=(1,))\n        n = img.size(0)\n        val_top1.update(prec1.item(), n)\n    return val_top1.avg\n    # print(f'[testing ...]: [test acc: {val_top1.avg}]')","metadata":{"id":"MpTOrCdQV-Sj","execution":{"iopub.status.busy":"2021-08-31T01:21:27.262945Z","iopub.execute_input":"2021-08-31T01:21:27.263262Z","iopub.status.idle":"2021-08-31T01:21:27.280980Z","shell.execute_reply.started":"2021-08-31T01:21:27.263236Z","shell.execute_reply":"2021-08-31T01:21:27.279165Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def compute_weight4training(org_weight, one_hot_label, num_classes):\n    weights = torch.from_numpy(org_weight).to(torch.float32).to(DEVICE)\n    weights = torch.unsqueeze(weights, 0)\n    weights = torch.tile(weights, [one_hot_label.shape[0], 1])*one_hot_label\n    weights = torch.sum(weights, 1)\n    weights = torch.unsqueeze(weights, 1)\n    weights = torch.tile(weights, [1, NUM_CLASSES])\n    return weights\n\n# cifarmodel=cifarModel( \n#         in_channels=3,\n#         num_layers=NUM_LAYERS, \n#         is_training=True, \n#         batch_norm_decay=0.9, \n#         batch_norm_epsilon=1e-5,\n#         version=RESNET_VERSION,\n#         num_classes=10, \n#         loss_type=LOSS_TYPE,\n#     ).to(DEVICE)\n\n\"\"\"===================there are three stage about training======================\"\"\"\n\"\"\"stage1:\"\"\"\nLOSS_TYPE = 'softmax'\nBEST_ACC = 0\ncifarmodel=cifarModel( \n        in_channels=3,\n        num_layers=NUM_LAYERS, \n        is_training=True, \n        batch_norm_decay=0.9, \n        batch_norm_epsilon=1e-5,\n        version=RESNET_VERSION,\n        num_classes=10, \n        loss_type=LOSS_TYPE,\n    ).to(DEVICE)\noptim1, sche1 = chose_optim(LOSS_TYPE, cifarmodel)\nfor epoch in range(TRAIN_EPOCH):\n    loss, train_top1, index = train_step(cifarmodel, train_dataloader, LOSS_TYPE, optim1, sche1)\n    if epoch % 5 == 0:\n        print('stage 1:[step: %.5d]'%(index*(epoch+1))+' [epoch: %.3d]'%(epoch)+'[EPOCH: %.3d]:'%(TRAIN_EPOCH)+' [train loss: %.2f]'%(loss)+'/[train acc: %.2f]'%(train_top1))\n    if epoch % EVAL_EPOCHS == 0:\n        val_top1 = test_step(cifarmodel, val_dataloader, LOSS_TYPE)\n        print('[testing ...]: [test acc: %2.2f]'%(val_top1))\n        if val_top1>BEST_ACC:\n            save_model(cifarmodel, SAVE_DIR, LOSS_TYPE)\n\n\"\"\"stage2:\"\"\"\nLOSS_TYPE = 'sigmoid'\nBEST_ACC = 0\ncifarmodel=cifarModel( \n        in_channels=3,\n        num_layers=NUM_LAYERS, \n        is_training=True, \n        batch_norm_decay=0.9, \n        batch_norm_epsilon=1e-5,\n        version=RESNET_VERSION,\n        num_classes=10, \n        loss_type=LOSS_TYPE,\n    ).to(DEVICE)\n\noptim2, sche2 = chose_optim(LOSS_TYPE, cifarmodel)\nfor epoch in range(TRAIN_EPOCH):\n    loss, train_top1, index = train_step(cifarmodel, train_dataloader, LOSS_TYPE, optim2, sche2)\n    if epoch % 5 == 0:\n        print('stage 2: [step: %.5d]'%(index*(epoch+1))+'[epoch: %.3d]'%(epoch)+'[EPOCH: %.3d]:'%(TRAIN_EPOCH)+' [train loss: %.2f]'%(loss)+'/[train acc: %.2f]'%(train_top1))\n    if epoch % EVAL_EPOCHS == 0:\n        val_top1 = test_step(cifarmodel, val_dataloader, LOSS_TYPE)\n        print('[testing ...]: [test acc: %2.2f]'%(val_top1))\n        if val_top1>BEST_ACC:\n            save_model(cifarmodel, SAVE_DIR, LOSS_TYPE)\n\n\"\"\"stage3:\"\"\"\nLOSS_TYPE = 'focal'\nBEST_ACC = 0\ncifarmodel=cifarModel( \n        in_channels=3,\n        num_layers=NUM_LAYERS, \n        is_training=True, \n        batch_norm_decay=0.9, \n        batch_norm_epsilon=1e-5,\n        version=RESNET_VERSION,\n        num_classes=10, \n        loss_type=LOSS_TYPE,\n    ).to(DEVICE)\n\noptim3, sche3 = chose_optim(LOSS_TYPE, cifarmodel)\nfor epoch in range(TRAIN_EPOCH):\n    loss, train_top1 = train_step(cifarmodel, train_dataloader, LOSS_TYPE, optim3, sche3)\n    if epoch % 5 == 0:\n        print('stage 3: [step: %.5d]'%(index*(epoch+1))+'[epoch: %.3d]'%(epoch)+'[EPOCH: %.3d]:'%(TRAIN_EPOCH)+' [train loss: %.2f]'%(loss)+'/[train acc: %.2f]'%(train_top1))\n    if epoch % EVAL_EPOCHS == 0:\n        val_top1 = test_step(cifarmodel, val_dataloader, LOSS_TYPE)\n        print('[testing ...]: [test acc: %2.2f]'%(val_top1))\n        if val_top1>BEST_ACC:\n            save_model(cifarmodel, SAVE_DIR, LOSS_TYPE)","metadata":{"id":"bvxFaUwWKQo5","outputId":"b2434137-a9dd-45d9-8012-1ebf9ea05d26","execution":{"iopub.status.busy":"2021-08-31T01:21:30.319469Z","iopub.execute_input":"2021-08-31T01:21:30.319798Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"stage 1: [epoch: 000][EPOCH: 200]: [train loss: 2.54]/[train acc: 2.51]\n[testing ...]: [test acc: 2.28]\nstage 1: [epoch: 005][EPOCH: 200]: [train loss: 1.83]/[train acc: 33.55]\n[testing ...]: [test acc: 31.78]\nstage 1: [epoch: 010][EPOCH: 200]: [train loss: 1.56]/[train acc: 42.01]\n[testing ...]: [test acc: 47.00]\nstage 1: [epoch: 015][EPOCH: 200]: [train loss: 1.37]/[train acc: 51.52]\n[testing ...]: [test acc: 47.54]\nstage 1: [epoch: 020][EPOCH: 200]: [train loss: 1.15]/[train acc: 57.93]\n[testing ...]: [test acc: 48.79]\nstage 1: [epoch: 025][EPOCH: 200]: [train loss: 1.03]/[train acc: 61.61]\n[testing ...]: [test acc: 54.46]\nstage 1: [epoch: 030][EPOCH: 200]: [train loss: 0.98]/[train acc: 63.49]\n[testing ...]: [test acc: 61.80]\nstage 1: [epoch: 035][EPOCH: 200]: [train loss: 0.84]/[train acc: 68.43]\n[testing ...]: [test acc: 65.05]\nstage 1: [epoch: 040][EPOCH: 200]: [train loss: 0.75]/[train acc: 71.34]\n[testing ...]: [test acc: 63.05]\nstage 1: [epoch: 045][EPOCH: 200]: [train loss: 0.70]/[train acc: 74.13]\n[testing ...]: [test acc: 66.98]\nstage 1: [epoch: 050][EPOCH: 200]: [train loss: 0.62]/[train acc: 75.81]\n[testing ...]: [test acc: 62.77]\nstage 1: [epoch: 055][EPOCH: 200]: [train loss: 0.58]/[train acc: 78.24]\n[testing ...]: [test acc: 56.06]\nstage 1: [epoch: 060][EPOCH: 200]: [train loss: 0.52]/[train acc: 79.21]\n[testing ...]: [test acc: 69.94]\nstage 1: [epoch: 065][EPOCH: 200]: [train loss: 0.56]/[train acc: 78.84]\n[testing ...]: [test acc: 67.26]\nstage 1: [epoch: 070][EPOCH: 200]: [train loss: 0.46]/[train acc: 81.66]\n[testing ...]: [test acc: 74.25]\nstage 1: [epoch: 075][EPOCH: 200]: [train loss: 0.47]/[train acc: 81.25]\n[testing ...]: [test acc: 67.69]\nstage 1: [epoch: 080][EPOCH: 200]: [train loss: 0.46]/[train acc: 82.13]\n[testing ...]: [test acc: 76.75]\nstage 1: [epoch: 085][EPOCH: 200]: [train loss: 0.43]/[train acc: 82.05]\n[testing ...]: [test acc: 69.94]\nstage 1: [epoch: 090][EPOCH: 200]: [train loss: 0.38]/[train acc: 84.60]\n[testing ...]: [test acc: 75.00]\nstage 1: [epoch: 095][EPOCH: 200]: [train loss: 0.48]/[train acc: 81.05]\n[testing ...]: [test acc: 68.58]\nstage 1: [epoch: 100][EPOCH: 200]: [train loss: 0.42]/[train acc: 83.01]\n[testing ...]: [test acc: 74.86]\nstage 1: [epoch: 105][EPOCH: 200]: [train loss: 0.38]/[train acc: 84.81]\n[testing ...]: [test acc: 74.43]\nstage 1: [epoch: 110][EPOCH: 200]: [train loss: 0.36]/[train acc: 84.78]\n[testing ...]: [test acc: 74.29]\nstage 1: [epoch: 115][EPOCH: 200]: [train loss: 0.31]/[train acc: 87.34]\n[testing ...]: [test acc: 73.57]\nstage 1: [epoch: 120][EPOCH: 200]: [train loss: 0.30]/[train acc: 87.52]\n[testing ...]: [test acc: 62.05]\nstage 1: [epoch: 125][EPOCH: 200]: [train loss: 0.33]/[train acc: 86.07]\n[testing ...]: [test acc: 70.26]\nstage 1: [epoch: 130][EPOCH: 200]: [train loss: 0.32]/[train acc: 86.85]\n[testing ...]: [test acc: 73.79]\nstage 1: [epoch: 135][EPOCH: 200]: [train loss: 0.49]/[train acc: 80.45]\n[testing ...]: [test acc: 74.54]\nstage 1: [epoch: 140][EPOCH: 200]: [train loss: 0.31]/[train acc: 87.19]\n[testing ...]: [test acc: 73.79]\nstage 1: [epoch: 145][EPOCH: 200]: [train loss: 0.29]/[train acc: 87.69]\n[testing ...]: [test acc: 76.25]\nstage 1: [epoch: 150][EPOCH: 200]: [train loss: 0.31]/[train acc: 86.45]\n[testing ...]: [test acc: 76.57]\nstage 1: [epoch: 155][EPOCH: 200]: [train loss: 0.28]/[train acc: 87.92]\n[testing ...]: [test acc: 76.89]\nstage 1: [epoch: 160][EPOCH: 200]: [train loss: 0.19]/[train acc: 91.67]\n[testing ...]: [test acc: 81.06]\nstage 1: [epoch: 165][EPOCH: 200]: [train loss: 0.10]/[train acc: 94.68]\n[testing ...]: [test acc: 82.42]\nstage 1: [epoch: 170][EPOCH: 200]: [train loss: 0.08]/[train acc: 95.60]\n[testing ...]: [test acc: 82.70]\nstage 1: [epoch: 175][EPOCH: 200]: [train loss: 0.08]/[train acc: 95.96]\n[testing ...]: [test acc: 82.49]\nstage 1: [epoch: 180][EPOCH: 200]: [train loss: 0.06]/[train acc: 96.80]\n[testing ...]: [test acc: 82.17]\nstage 1: [epoch: 185][EPOCH: 200]: [train loss: 0.07]/[train acc: 96.53]\n[testing ...]: [test acc: 82.38]\nstage 1: [epoch: 190][EPOCH: 200]: [train loss: 0.06]/[train acc: 96.44]\n[testing ...]: [test acc: 82.31]\nstage 1: [epoch: 195][EPOCH: 200]: [train loss: 0.06]/[train acc: 96.59]\n[testing ...]: [test acc: 82.35]\nstage 2: [epoch: 000][EPOCH: 200]: [train loss: 1.10]/[train acc: 1.16]\n[testing ...]: [test acc: 1.28]\nstage 2: [epoch: 005][EPOCH: 200]: [train loss: 0.70]/[train acc: 30.74]\n[testing ...]: [test acc: 24.43]\nstage 2: [epoch: 010][EPOCH: 200]: [train loss: 0.61]/[train acc: 41.99]\n[testing ...]: [test acc: 41.69]\nstage 2: [epoch: 015][EPOCH: 200]: [train loss: 0.51]/[train acc: 53.97]\n[testing ...]: [test acc: 55.03]\nstage 2: [epoch: 020][EPOCH: 200]: [train loss: 0.45]/[train acc: 60.77]\n[testing ...]: [test acc: 57.70]\nstage 2: [epoch: 025][EPOCH: 200]: [train loss: 0.39]/[train acc: 65.73]\n[testing ...]: [test acc: 62.55]\nstage 2: [epoch: 030][EPOCH: 200]: [train loss: 0.34]/[train acc: 70.90]\n[testing ...]: [test acc: 62.59]\nstage 2: [epoch: 035][EPOCH: 200]: [train loss: 0.30]/[train acc: 74.00]\n[testing ...]: [test acc: 44.69]\nstage 2: [epoch: 040][EPOCH: 200]: [train loss: 0.35]/[train acc: 69.40]\n[testing ...]: [test acc: 62.77]\nstage 2: [epoch: 045][EPOCH: 200]: [train loss: 0.26]/[train acc: 77.47]\n[testing ...]: [test acc: 71.15]\nstage 2: [epoch: 050][EPOCH: 200]: [train loss: 0.24]/[train acc: 79.08]\n[testing ...]: [test acc: 69.29]\nstage 2: [epoch: 055][EPOCH: 200]: [train loss: 0.23]/[train acc: 80.44]\n[testing ...]: [test acc: 66.87]\nstage 2: [epoch: 060][EPOCH: 200]: [train loss: 0.23]/[train acc: 80.16]\n[testing ...]: [test acc: 70.01]\nstage 2: [epoch: 065][EPOCH: 200]: [train loss: 0.21]/[train acc: 81.13]\n[testing ...]: [test acc: 70.86]\nstage 2: [epoch: 070][EPOCH: 200]: [train loss: 0.19]/[train acc: 82.60]\n[testing ...]: [test acc: 76.03]\nstage 2: [epoch: 075][EPOCH: 200]: [train loss: 0.19]/[train acc: 82.98]\n[testing ...]: [test acc: 73.00]\nstage 2: [epoch: 080][EPOCH: 200]: [train loss: 0.17]/[train acc: 84.78]\n[testing ...]: [test acc: 74.93]\nstage 2: [epoch: 085][EPOCH: 200]: [train loss: 0.17]/[train acc: 84.26]\n[testing ...]: [test acc: 76.96]\nstage 2: [epoch: 090][EPOCH: 200]: [train loss: 0.17]/[train acc: 84.31]\n[testing ...]: [test acc: 57.88]\nstage 2: [epoch: 095][EPOCH: 200]: [train loss: 0.15]/[train acc: 86.79]\n[testing ...]: [test acc: 68.22]\nstage 2: [epoch: 100][EPOCH: 200]: [train loss: 0.14]/[train acc: 87.07]\n[testing ...]: [test acc: 73.89]\nstage 2: [epoch: 105][EPOCH: 200]: [train loss: 0.14]/[train acc: 87.00]\n[testing ...]: [test acc: 67.33]\nstage 2: [epoch: 110][EPOCH: 200]: [train loss: 0.17]/[train acc: 84.87]\n[testing ...]: [test acc: 74.86]\nstage 2: [epoch: 115][EPOCH: 200]: [train loss: 0.15]/[train acc: 86.68]\n[testing ...]: [test acc: 69.76]\nstage 2: [epoch: 120][EPOCH: 200]: [train loss: 0.16]/[train acc: 85.08]\n[testing ...]: [test acc: 75.11]\nstage 2: [epoch: 125][EPOCH: 200]: [train loss: 0.16]/[train acc: 85.80]\n[testing ...]: [test acc: 60.02]\nstage 2: [epoch: 130][EPOCH: 200]: [train loss: 0.13]/[train acc: 87.61]\n[testing ...]: [test acc: 79.03]\nstage 2: [epoch: 135][EPOCH: 200]: [train loss: 0.14]/[train acc: 88.28]\n[testing ...]: [test acc: 73.54]\nstage 2: [epoch: 140][EPOCH: 200]: [train loss: 0.16]/[train acc: 84.83]\n[testing ...]: [test acc: 77.03]\nstage 2: [epoch: 145][EPOCH: 200]: [train loss: 0.13]/[train acc: 87.36]\n[testing ...]: [test acc: 74.00]\nstage 2: [epoch: 150][EPOCH: 200]: [train loss: 0.15]/[train acc: 86.58]\n[testing ...]: [test acc: 76.21]\nstage 2: [epoch: 155][EPOCH: 200]: [train loss: 0.13]/[train acc: 88.42]\n[testing ...]: [test acc: 75.64]\nstage 2: [epoch: 160][EPOCH: 200]: [train loss: 0.10]/[train acc: 90.05]\n[testing ...]: [test acc: 80.56]\nstage 2: [epoch: 165][EPOCH: 200]: [train loss: 0.06]/[train acc: 93.92]\n[testing ...]: [test acc: 82.10]\nstage 2: [epoch: 170][EPOCH: 200]: [train loss: 0.05]/[train acc: 94.91]\n[testing ...]: [test acc: 81.88]\nstage 2: [epoch: 175][EPOCH: 200]: [train loss: 0.04]/[train acc: 95.67]\n[testing ...]: [test acc: 82.49]\nstage 2: [epoch: 180][EPOCH: 200]: [train loss: 0.04]/[train acc: 96.02]\n[testing ...]: [test acc: 82.13]\nstage 2: [epoch: 185][EPOCH: 200]: [train loss: 0.04]/[train acc: 95.79]\n[testing ...]: [test acc: 81.70]\nstage 2: [epoch: 190][EPOCH: 200]: [train loss: 0.04]/[train acc: 95.83]\n[testing ...]: [test acc: 81.60]\nstage 2: [epoch: 195][EPOCH: 200]: [train loss: 0.04]/[train acc: 95.88]\n[testing ...]: [test acc: 81.70]\nstage 3: [epoch: 000][EPOCH: 200]: [train loss: 0.60]/[train acc: 23.17]\n[testing ...]: [test acc: 23.25]\nstage 3: [epoch: 005][EPOCH: 200]: [train loss: 0.36]/[train acc: 32.05]\n[testing ...]: [test acc: 43.22]\nstage 3: [epoch: 010][EPOCH: 200]: [train loss: 0.29]/[train acc: 48.53]\n[testing ...]: [test acc: 32.03]\nstage 3: [epoch: 015][EPOCH: 200]: [train loss: 0.25]/[train acc: 56.14]\n[testing ...]: [test acc: 51.85]\nstage 3: [epoch: 020][EPOCH: 200]: [train loss: 0.22]/[train acc: 62.72]\n[testing ...]: [test acc: 58.52]\nstage 3: [epoch: 025][EPOCH: 200]: [train loss: 0.19]/[train acc: 68.27]\n[testing ...]: [test acc: 50.04]\nstage 3: [epoch: 030][EPOCH: 200]: [train loss: 0.17]/[train acc: 71.37]\n[testing ...]: [test acc: 62.62]\nstage 3: [epoch: 035][EPOCH: 200]: [train loss: 0.16]/[train acc: 73.42]\n[testing ...]: [test acc: 68.97]\nstage 3: [epoch: 040][EPOCH: 200]: [train loss: 0.14]/[train acc: 76.49]\n[testing ...]: [test acc: 63.41]\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\ndef save_model(model, save_dir, stage):\n    save_path = os.path.join(save_dir, LOSS_TYPE+'.pth')\n    torch.save(model.state_dict(), save_path)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:18:48.133490Z","iopub.execute_input":"2021-08-31T01:18:48.133835Z","iopub.status.idle":"2021-08-31T01:18:48.138821Z","shell.execute_reply.started":"2021-08-31T01:18:48.133779Z","shell.execute_reply":"2021-08-31T01:18:48.137720Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-08-31T01:20:29.826737Z","iopub.execute_input":"2021-08-31T01:20:29.827118Z","iopub.status.idle":"2021-08-31T01:20:29.835064Z","shell.execute_reply.started":"2021-08-31T01:20:29.827072Z","shell.execute_reply":"2021-08-31T01:20:29.834202Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"[0.1, 0.010000000000000002, 1e-05]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}